## lang.conf - linguistic parsing configuration


## Spacy token normalizers
#
# base NLP
[map_filter_token_normalizer]
class_name = zensols.nlp.MapTokenNormalizer
# add the split token mapper to have consistent token symmetry between the
# vanilla langres and mednlp_langres parsers as the MedCAT parser splits
# entities; see section `mednlp_map_filter_token_normalizer`
mapper_class_list = list: filter_token_mapper, split_ent_token_mapper

# medical nlp
[mednlp_map_filter_token_normalizer]
class_name = zensols.nlp.MapTokenNormalizer
mapper_class_list = list: filter_token_mapper
embed_entities = False


## MedCat resources
#
[medcat_resource]
class_name = zensols.mednlp.MedCatResource
installer = instance: medcat_installer
vocab_resource = instance: medcat_vocab_resource
cdb_resource = instance: medcat_cdb_resource
mc_status_resource = instance: medcat_status_resource
umls_tuis = instance: medcat_umls_tuis
umls_groups = instance: medcal_uml_groups
requirements_dir = resource(zensols.mednlp): resources/requirements
cat_config = dict: {'general': {'spacy_model': 'en_core_sci_md'}}

[mednlp_library]
class_name = zensols.mednlp.MedicalLibrary
medcat_resource = instance: medcat_resource
#entity_linker_resource = instance: entity_linker_resource

[mednlp_doc_parser]
class_name = zensols.mednlp.MedicalFeatureDocumentParser
lang = ${doc_parser:lang}
model_name = ${doc_parser:model_name}
token_normalizer = instance: mednlp_map_filter_token_normalizer
medcat_resource = instance: medcat_resource
# set all features (override in your own configuration if you want them all)
token_feature_ids = eval({'import': ['zensols.nlp as n', 'zensols.mednlp as m']}):
    (n.FeatureToken.FEATURE_IDS | m.MedicalFeatureToken.FEATURE_IDS) - \
    {'tuis', 'tui_descs_'}

[mednlp_combine_doc_parser]
class_name = zensols.nlp.MappingCombinerFeatureDocumentParser
target_parser = instance: mednlp_doc_parser
source_parsers = instance: list: doc_parser
# only entities are missing from the medical parser output
overwrite_features = list: ent, ent_
# only map token level instead of sentence
merge_sentences = False
# absolute document based indexes shouldn't change
validate_features = set: idx
